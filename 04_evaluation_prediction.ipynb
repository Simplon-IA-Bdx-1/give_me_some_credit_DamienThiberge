{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération de l'ap de bigml\n",
    "\n",
    "from bigml.api import BigML\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pan\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#charge de l'api bigml pour pouvoir faire appel à ces fonctions\n",
    "\n",
    "api = BigML(project='project/5d94a451eba31d46690001cf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### récupération du fichier train full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération du fichier csv bigml à traiter\n",
    "train_full = api.create_source('./train_full.csv')\n",
    "\n",
    "#test des sources\n",
    "api.ok(train_full)\n",
    "\n",
    "#création dataset depuis le fichier csv importer précédement\n",
    "train_full_dataset = api.create_dataset(train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split du fichier train full "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split du train full\n",
    "\n",
    "train_dataset = api.create_dataset(\n",
    "    train_full_dataset, {\"name\": \"Train (80%)\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"Full train\"})\n",
    "validation_dataset = api.create_dataset(\n",
    "    train_full_dataset, {\"name\": \"Train (20%)\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"Full train\",\n",
    "                     \"out_of_bag\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split du train\n",
    "def split(percent):\n",
    "    train_split = api.create_dataset(\n",
    "                    train_full_dataset, {\"name\": \"Train (80%)\",\n",
    "                     \"sample_rate\": percent, \"seed\": \"Full train\"})\n",
    "    api.ok(train_split)\n",
    "    return train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:55,432: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:55,439: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:56,449: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:56,457: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:57,466: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:57,473: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:58,501: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:58,508: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:59,514: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:30:59,524: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:00,544: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:00,557: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:01,612: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:01,619: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:02,662: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:02,668: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:03,714: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:03,720: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:04,698: You have reached the max number of parallel tasks\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09 20:31:04,700: The resource couldn't be created: {'code': 402, 'status': {'code': -1108, 'message': 'You have reached the max number of parallel tasks'}}\n"
     ]
    }
   ],
   "source": [
    "#train suivant les differents percent\n",
    "split_10 = split(1/10)\n",
    "split_20 = split(2/10)\n",
    "split_30 = split(3/10)\n",
    "split_40 = split(4/10)\n",
    "split_50 = split(5/10)\n",
    "split_60 = split(6/10)\n",
    "split_70 = split(7/10)\n",
    "split_80 = split(8/10)\n",
    "split_90 = split(9/10)\n",
    "split_100 = split(10/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calcul des models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de calcul du model ensemble\n",
    "def ensemble(train):\n",
    "    ensemble = api.create_ensemble(train,{\"objective_field\":\"SeriousDlqin2yrs\"})\n",
    "    api.ok(ensemble)\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de calcul du model deepnet\n",
    "def deepnet(train):\n",
    "    deepnet = api.create_deepnet(train,{\"objective_field\":\"SeriousDlqin2yrs\"})\n",
    "    api.ok(deepnet)\n",
    "    return deepnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to parse a resource string or structure.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-439cf8398b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mensemble_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mensemble_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mensemble_30\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mensemble_40\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0e794eb010e1>\u001b[0m in \u001b[0;36mensemble\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fonction de calcul du model ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"objective_field\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"SeriousDlqin2yrs\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bigml/ensemblehandler.py\u001b[0m in \u001b[0;36mcreate_ensemble\u001b[0;34m(self, datasets, args, wait_time, retries)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         create_args = self._set_create_from_datasets_args(\n\u001b[0;32m---> 57\u001b[0;31m             datasets, args=args, wait_time=wait_time, retries=retries)\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bigml/resourcehandler.py\u001b[0m in \u001b[0;36m_set_create_from_datasets_args\u001b[0;34m(self, datasets, args, wait_time, retries, key)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morigin_datasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             check_resource_type(dataset, c.DATASET_PATH,\n\u001b[0;32m--> 542\u001b[0;31m                                 message=(\"A dataset id is needed to create\"\n\u001b[0m\u001b[1;32m    543\u001b[0m                                          \" the resource.\"))\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bigml/resourcehandler.py\u001b[0m in \u001b[0;36mcheck_resource_type\u001b[0;34m(resource, expected_resource, message)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mresource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mresource_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_resource_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpected_resources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\nFound %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bigml/resourcehandler.py\u001b[0m in \u001b[0;36mget_resource_type\u001b[0;34m(resource)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mresource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resource'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to parse a resource string or structure.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresource_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_re\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESOURCE_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresource_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to parse a resource string or structure."
     ]
    }
   ],
   "source": [
    "# model ensemble\n",
    "ensemble_10 = ensemble(split_10)\n",
    "ensemble_20 = ensemble(split_20)\n",
    "ensemble_30 = ensemble(split_30)\n",
    "ensemble_40 = ensemble(split_40)\n",
    "ensemble_50 = ensemble(split_50)\n",
    "ensemble_60 = ensemble(split_60)\n",
    "ensemble_70 = ensemble(split_70)\n",
    "ensemble_80 = ensemble(split_80)\n",
    "ensemble_90 = ensemble(split_90)\n",
    "ensemble_100 = ensemble(split_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model deepnet\n",
    "deepnet_10 = deepnet(split_10)\n",
    "deepnet_20 = deepnet(split_20)\n",
    "deepnet_30 = deepnet(split_30)\n",
    "deepnet_40 = deepnet(split_40)\n",
    "deepnet_50 = deepnet(split_50)\n",
    "deepnet_60 = deepnet(split_60)\n",
    "deepnet_70 = deepnet(split_70)\n",
    "deepnet_80 = deepnet(split_80)\n",
    "deepnet_90 = deepnet(split_90)\n",
    "deepnet_100 = deepnet(split_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prédictions à partir d'un model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchprediction(model, train):\n",
    "    batch_prediction = api.create_batch_prediction(model, train,{\"header\": True, \"all_fields\": True,\n",
    "                                                  \"prediction_name\": \"my_prediction\", \"probabilities\": True})\n",
    "    api.ok(batch_prediction)\n",
    "    return batch_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 10 percent\n",
    "prediction_ens_val_10 = batchprediction(ensemble_10, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_10,filename='BatchPrediction/prediction_ens_val_10.csv')\n",
    "\n",
    "prediction_dee_val_10 = batchprediction(deepnet_10, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_10,filename='BatchPrediction/prediction_dee_val_10.csv')\n",
    "\n",
    "prediction_ens_spl_10 = batchprediction(ensemble_10, split_10)\n",
    "api.download_batch_prediction(prediction_ens_spl_10,filename='BatchPrediction/prediction_ens_spl_10.csv')\n",
    "\n",
    "prediction_dee_spl_10 = batchprediction(deepnet_10, split_10)\n",
    "api.download_batch_prediction(prediction_dee_spl_10,filename='BatchPrediction/prediction_dee_spl_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 20 percent\n",
    "prediction_ens_val_20 = batchprediction(ensemble_20, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_20,filename='BatchPrediction/prediction_ens_val_20.csv')\n",
    "\n",
    "prediction_dee_val_20 = batchprediction(deepnet_20, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_20,filename='BatchPrediction/prediction_dee_val_20.csv')\n",
    "\n",
    "prediction_ens_spl_20 = batchprediction(ensemble_20, split_20)\n",
    "api.download_batch_prediction(prediction_ens_spl_20,filename='BatchPrediction/prediction_ens_spl_20.csv')\n",
    "\n",
    "prediction_dee_spl_20 = batchprediction(deepnet_20, split_20)\n",
    "api.download_batch_prediction(prediction_dee_spl_20,filename='BatchPrediction/prediction_dee_spl_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 30 percent\n",
    "prediction_ens_val_30 = batchprediction(ensemble_30, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_30,filename='BatchPrediction/prediction_ens_val_30.csv')\n",
    "\n",
    "prediction_dee_val_30 = batchprediction(deepnet_30, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_30,filename='BatchPrediction/prediction_dee_val_30.csv')\n",
    "\n",
    "prediction_ens_spl_30 = batchprediction(ensemble_30, split_30)\n",
    "api.download_batch_prediction(prediction_ens_spl_30,filename='BatchPrediction/prediction_ens_spl_30.csv')\n",
    "\n",
    "prediction_dee_spl_30 = batchprediction(deepnet_30, split_30)\n",
    "api.download_batch_prediction(prediction_dee_spl_30,filename='BatchPrediction/prediction_dee_spl_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 40 percent\n",
    "prediction_ens_val_40 = batchprediction(ensemble_40, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_40,filename='BatchPrediction/prediction_ens_val_40.csv')\n",
    "\n",
    "prediction_dee_val_40 = batchprediction(deepnet_40, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_40,filename='BatchPrediction/prediction_dee_val_40.csv')\n",
    "\n",
    "prediction_ens_spl_40 = batchprediction(ensemble_40, split_40)\n",
    "api.download_batch_prediction(prediction_ens_spl_40,filename='BatchPrediction/prediction_ens_spl_40.csv')\n",
    "\n",
    "prediction_dee_spl_40 = batchprediction(deepnet_40, split_40)\n",
    "api.download_batch_prediction(prediction_dee_spl_40,filename='BatchPrediction/prediction_dee_spl_40.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 50 percent\n",
    "prediction_ens_val_50 = batchprediction(ensemble_50, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_50,filename='BatchPrediction/prediction_ens_val_50.csv')\n",
    "\n",
    "prediction_dee_val_50 = batchprediction(deepnet_50, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_50,filename='BatchPrediction/prediction_dee_val_50.csv')\n",
    "\n",
    "prediction_ens_spl_50 = batchprediction(ensemble_50, split_50)\n",
    "api.download_batch_prediction(prediction_ens_spl_50,filename='BatchPrediction/prediction_ens_spl_50.csv')\n",
    "\n",
    "prediction_dee_spl_50 = batchprediction(deepnet_50, split_50)\n",
    "api.download_batch_prediction(prediction_dee_spl_50,filename='BatchPrediction/prediction_dee_spl_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 60 percent\n",
    "prediction_ens_val_60 = batchprediction(ensemble_60, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_60,filename='BatchPrediction/prediction_ens_val_60.csv')\n",
    "\n",
    "prediction_dee_val_60 = batchprediction(deepnet_60, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_60,filename='BatchPrediction/prediction_dee_val_60.csv')\n",
    "\n",
    "prediction_ens_spl_60 = batchprediction(ensemble_60, split_60)\n",
    "api.download_batch_prediction(prediction_ens_spl_60,filename='BatchPrediction/prediction_ens_spl_60.csv')\n",
    "\n",
    "prediction_dee_spl_60 = batchprediction(deepnet_60, split_60)\n",
    "api.download_batch_prediction(prediction_dee_spl_60,filename='BatchPrediction/prediction_dee_spl_60.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 70 percent\n",
    "prediction_ens_val_70 = batchprediction(ensemble_70, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_70,filename='BatchPrediction/prediction_ens_val_70.csv')\n",
    "\n",
    "prediction_dee_val_70 = batchprediction(deepnet_70, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_70,filename='BatchPrediction/prediction_dee_val_70.csv')\n",
    "\n",
    "prediction_ens_spl_70 = batchprediction(ensemble_70, split_70)\n",
    "api.download_batch_prediction(prediction_ens_spl_70,filename='BatchPrediction/prediction_ens_spl_70.csv')\n",
    "\n",
    "prediction_dee_spl_70 = batchprediction(deepnet_70, split_70)\n",
    "api.download_batch_prediction(prediction_dee_spl_70,filename='BatchPrediction/prediction_dee_spl_70.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 10 percent\n",
    "prediction_ens_val_80 = batchprediction(ensemble_80, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_80,filename='BatchPrediction/prediction_ens_val_80.csv')\n",
    "\n",
    "prediction_dee_val_80 = batchprediction(deepnet_80, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_80,filename='BatchPrediction/prediction_dee_val_80.csv')\n",
    "\n",
    "prediction_ens_spl_80 = batchprediction(ensemble_80, split_80)\n",
    "api.download_batch_prediction(prediction_ens_spl_80,filename='BatchPrediction/prediction_ens_spl_80.csv')\n",
    "\n",
    "prediction_dee_spl_80 = batchprediction(deepnet_80, split_80)\n",
    "api.download_batch_prediction(prediction_dee_spl_80,filename='BatchPrediction/prediction_dee_spl_80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 90 percent\n",
    "prediction_ens_val_90 = batchprediction(ensemble_90, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_90,filename='BatchPrediction/prediction_ens_val_90.csv')\n",
    "\n",
    "prediction_dee_val_90 = batchprediction(deepnet_90, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_90,filename='BatchPrediction/prediction_dee_val_90.csv')\n",
    "\n",
    "prediction_ens_spl_90 = batchprediction(ensemble_90, split_90)\n",
    "api.download_batch_prediction(prediction_ens_spl_90,filename='BatchPrediction/prediction_ens_spl_90.csv')\n",
    "\n",
    "prediction_dee_spl_90 = batchprediction(deepnet_90, split_90)\n",
    "api.download_batch_prediction(prediction_dee_spl_90,filename='BatchPrediction/prediction_dee_spl_90.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des prédictions avec 100 percent\n",
    "prediction_ens_val_100 = batchprediction(ensemble_100, validation_dataset)\n",
    "api.download_batch_prediction(prediction_ens_val_100,filename='BatchPrediction/prediction_ens_val_100.csv')\n",
    "\n",
    "prediction_dee_val_100 = batchprediction(deepnet_100, validation_dataset)\n",
    "api.download_batch_prediction(prediction_dee_val_100,filename='BatchPrediction/prediction_dee_val_100.csv')\n",
    "\n",
    "prediction_ens_spl_100 = batchprediction(ensemble_100, split_100)\n",
    "api.download_batch_prediction(prediction_ens_spl_100,filename='BatchPrediction/prediction_ens_spl_100.csv')\n",
    "\n",
    "prediction_dee_spl_100 = batchprediction(deepnet_100, split_100)\n",
    "api.download_batch_prediction(prediction_dee_spl_100,filename='BatchPrediction/prediction_dee_spl_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calcul de l'auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de calcul\n",
    "def auc(csv):\n",
    "    actual = csv['SeriousDlqin2yrs']\n",
    "    pred = csv['1 probability']\n",
    "    auc = np.float64(roc_auc_score(actual, pred))\n",
    "    return np.float64(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## création de liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste ensemble avec validation\n",
    "prediction_ens_val_10 = read_csv('BatchPrediction/prediction_ens_val_10.csv', index_col = 0)\n",
    "prediction_ens_val_20 = read_csv('BatchPrediction/prediction_ens_val_20.csv', index_col = 0)\n",
    "prediction_ens_val_30 = read_csv('BatchPrediction/prediction_ens_val_30.csv', index_col = 0)\n",
    "prediction_ens_val_40 = read_csv('BatchPrediction/prediction_ens_val_40.csv', index_col = 0)\n",
    "prediction_ens_val_50 = read_csv('BatchPrediction/prediction_ens_val_50.csv', index_col = 0)\n",
    "prediction_ens_val_60 = read_csv('BatchPrediction/prediction_ens_val_60.csv', index_col = 0)\n",
    "prediction_ens_val_70 = read_csv('BatchPrediction/prediction_ens_val_70.csv', index_col = 0)\n",
    "prediction_ens_val_80 = read_csv('BatchPrediction/prediction_ens_val_80.csv', index_col = 0)\n",
    "prediction_ens_val_90 = read_csv('BatchPrediction/prediction_ens_val_90.csv', index_col = 0)\n",
    "prediction_ens_val_100 = read_csv('BatchPrediction/prediction_ens_val_100.csv', index_col = 0)\n",
    "\n",
    "auc_ens_val = [\n",
    "    auc(prediction_ens_val_10),\n",
    "    auc(prediction_ens_val_20),\n",
    "    auc(prediction_ens_val_30),\n",
    "    auc(prediction_ens_val_40),\n",
    "    auc(prediction_ens_val_50),\n",
    "    auc(prediction_ens_val_60),\n",
    "    auc(prediction_ens_val_70),\n",
    "    auc(prediction_ens_val_80),\n",
    "    auc(prediction_ens_val_90),\n",
    "    auc(prediction_ens_val_100)\n",
    "]\n",
    "\n",
    "print(auc_ens_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste ensemble avec split\n",
    "prediction_ens_spl_10 = read_csv('BatchPrediction/prediction_ens_spl_10.csv', index_col = 0)\n",
    "prediction_ens_spl_20 = read_csv('BatchPrediction/prediction_ens_spl_20.csv', index_col = 0)\n",
    "prediction_ens_spl_30 = read_csv('BatchPrediction/prediction_ens_spl_30.csv', index_col = 0)\n",
    "prediction_ens_spl_40 = read_csv('BatchPrediction/prediction_ens_spl_40.csv', index_col = 0)\n",
    "prediction_ens_spl_50 = read_csv('BatchPrediction/prediction_ens_spl_50.csv', index_col = 0)\n",
    "prediction_ens_spl_60 = read_csv('BatchPrediction/prediction_ens_spl_60.csv', index_col = 0)\n",
    "prediction_ens_spl_70 = read_csv('BatchPrediction/prediction_ens_spl_70.csv', index_col = 0)\n",
    "prediction_ens_spl_80 = read_csv('BatchPrediction/prediction_ens_spl_80.csv', index_col = 0)\n",
    "prediction_ens_spl_90 = read_csv('BatchPrediction/prediction_ens_spl_90.csv', index_col = 0)\n",
    "prediction_ens_spl_100 = read_csv('BatchPrediction/prediction_ens_spl_100.csv', index_col = 0)\n",
    "\n",
    "auc_ens_spl = [\n",
    "    auc(prediction_ens_spl_10),\n",
    "    auc(prediction_ens_spl_20),\n",
    "    auc(prediction_ens_spl_30),\n",
    "    auc(prediction_ens_spl_40),\n",
    "    auc(prediction_ens_spl_50),\n",
    "    auc(prediction_ens_spl_60),\n",
    "    auc(prediction_ens_spl_70),\n",
    "    auc(prediction_ens_spl_80),\n",
    "    auc(prediction_ens_spl_90),\n",
    "    auc(prediction_ens_spl_100)\n",
    "]\n",
    "\n",
    "print(auc_ens_spl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste deepnet avec validation\n",
    "prediction_dee_val_10 = read_csv('BatchPrediction/prediction_dee_val_10.csv', index_col = 0)\n",
    "prediction_dee_val_20 = read_csv('BatchPrediction/prediction_dee_val_20.csv', index_col = 0)\n",
    "prediction_dee_val_30 = read_csv('BatchPrediction/prediction_dee_val_30.csv', index_col = 0)\n",
    "prediction_dee_val_40 = read_csv('BatchPrediction/prediction_dee_val_40.csv', index_col = 0)\n",
    "prediction_dee_val_50 = read_csv('BatchPrediction/prediction_dee_val_50.csv', index_col = 0)\n",
    "prediction_dee_val_60 = read_csv('BatchPrediction/prediction_dee_val_60.csv', index_col = 0)\n",
    "prediction_dee_val_70 = read_csv('BatchPrediction/prediction_dee_val_70.csv', index_col = 0)\n",
    "prediction_dee_val_80 = read_csv('BatchPrediction/prediction_dee_val_80.csv', index_col = 0)\n",
    "prediction_dee_val_90 = read_csv('BatchPrediction/prediction_dee_val_90.csv', index_col = 0)\n",
    "prediction_dee_val_100 = read_csv('BatchPrediction/prediction_dee_val_100.csv', index_col = 0)\n",
    "\n",
    "auc_dee_val = [\n",
    "    auc(prediction_dee_val_10),\n",
    "    auc(prediction_dee_val_20),\n",
    "    auc(prediction_dee_val_30),\n",
    "    auc(prediction_dee_val_40),\n",
    "    auc(prediction_dee_val_50),\n",
    "    auc(prediction_dee_val_60),\n",
    "    auc(prediction_dee_val_70),\n",
    "    auc(prediction_dee_val_80),\n",
    "    auc(prediction_dee_val_90),\n",
    "    auc(prediction_dee_val_100)\n",
    "]\n",
    "\n",
    "print(auc_dee_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste deepnet avec split\n",
    "prediction_dee_spl_10 = read_csv('BatchPrediction/prediction_dee_spl_10.csv', index_col = 0)\n",
    "prediction_dee_spl_20 = read_csv('BatchPrediction/prediction_dee_spl_20.csv', index_col = 0)\n",
    "prediction_dee_spl_30 = read_csv('BatchPrediction/prediction_dee_spl_30.csv', index_col = 0)\n",
    "prediction_dee_spl_40 = read_csv('BatchPrediction/prediction_dee_spl_40.csv', index_col = 0)\n",
    "prediction_dee_spl_50 = read_csv('BatchPrediction/prediction_dee_spl_50.csv', index_col = 0)\n",
    "prediction_dee_spl_60 = read_csv('BatchPrediction/prediction_dee_spl_60.csv', index_col = 0)\n",
    "prediction_dee_spl_70 = read_csv('BatchPrediction/prediction_dee_spl_70.csv', index_col = 0)\n",
    "prediction_dee_spl_80 = read_csv('BatchPrediction/prediction_dee_spl_80.csv', index_col = 0)\n",
    "prediction_dee_spl_90 = read_csv('BatchPrediction/prediction_dee_spl_90.csv', index_col = 0)\n",
    "prediction_dee_spl_100 = read_csv('BatchPrediction/prediction_dee_spl_100.csv', index_col = 0)\n",
    "\n",
    "auc_dee_spl = [\n",
    "    auc(prediction_dee_spl_10),\n",
    "    auc(prediction_dee_spl_20),\n",
    "    auc(prediction_dee_spl_30),\n",
    "    auc(prediction_dee_spl_40),\n",
    "    auc(prediction_dee_spl_50),\n",
    "    auc(prediction_dee_spl_60),\n",
    "    auc(prediction_dee_spl_70),\n",
    "    auc(prediction_dee_spl_80),\n",
    "    auc(prediction_dee_spl_90),\n",
    "    auc(prediction_dee_spl_100)\n",
    "]\n",
    "\n",
    "print(auc_dee_spl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taille du train pour déterminer l'axe des abscisses des graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "train_size = []\n",
    "while n <= 100:\n",
    "    train_size_1 = 120000*(n/100)\n",
    "    train_size.append(train_size_1)\n",
    "    n += 10\n",
    "\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance ensemble train sur validation\n",
    "plt.grid()\n",
    "plt.axhline(y=0.87, color = 'red', label=\"Desired Performance\")\n",
    "plt.ylim(0.8,0.9)\n",
    "plt.plot(train_size, auc_ens_val, label= \"Ensemble_sur_validation\")\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de creation de graphe en fonction des pred\n",
    "def graph(list1, list2, list3):\n",
    "    plt.grid()\n",
    "    plt.axhline(y=0.87, color= 'red', label=\"Desired Performance\")\n",
    "    plt.rcParams['figure.figsize'] = [15 , 6]\n",
    "    plt.ylim(0.80,1)\n",
    "    plt.plot(list1, list2, color= 'blue')\n",
    "    plt.plot(list1, list3, color= 'green')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## affichage des graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model ensemble (bleu) vs deepnet (vert) sur validation\n",
    "graph(train_size, auc_ens_val, auc_dee_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model ensemble sur validation (bleu) vs sur split (vert)\n",
    "graph(train_size, auc_ens_val, auc_ens_spl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model deepnet sur validation (bleu) vs sur split (vert)\n",
    "graph(train_size, auc_dee_val, auc_dee_spl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
