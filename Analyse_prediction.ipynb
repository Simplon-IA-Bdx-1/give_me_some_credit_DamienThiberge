{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des résultats de la  prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#récupération de l'ap de bigml\n",
    "\n",
    "from bigml.api import BigML\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pan\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BIGML_USERNAME=damienthiberge\n",
      "env: BIGML_API_KEY=d92377e535638e44239dc49238540477263e1bff\n"
     ]
    }
   ],
   "source": [
    "#récupération des identifiants du projet de bigml\n",
    "\n",
    "%env BIGML_USERNAME=damienthiberge\n",
    "%env BIGML_API_KEY=d92377e535638e44239dc49238540477263e1bff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#charge de l'api bigml pour pouvoir faire appel à ces fonctions\n",
    "\n",
    "api = BigML()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### récupération du fichier train full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération du fichier csv bigml à traiter\n",
    "\n",
    "train_full = api.create_source('./train_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test des sources\n",
    "\n",
    "api.ok(train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#création dataset depuis le fichier csv importer précédement\n",
    "\n",
    "train_full_dataset = api.create_dataset(train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split du fichier train full afin d'entrainer la machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split du train full\n",
    "\n",
    "train_dataset = api.create_dataset(\n",
    "    train_full_dataset, {\"name\": \"Train (80%)\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"Full train\"})\n",
    "validation_dataset = api.create_dataset(\n",
    "    train_full_dataset, {\"name\": \"Train (20%)\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"Full train\",\n",
    "                     \"out_of_bag\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### création du model puis batch prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation d'un ensemble à partir de train \n",
    "\n",
    "ensemble = api.create_ensemble([train_dataset],{\"objective_field\":\"SeriousDlqin2yrs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch prédiction\n",
    "\n",
    "batch_prediction = api.create_batch_prediction(ensemble, validation_dataset, {\"all_fields\":True, \"probabilities\":True, 'prediction_name':'Prediction'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test prediction\n",
    "\n",
    "api.ok(batch_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### récupération csv de la prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../handson-ml/predictions_error.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#telechargement de la prédiction\n",
    "\n",
    "api.download_batch_prediction(batch_prediction,\n",
    "    filename='../../handson-ml/predictions_error.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mise en forme de la prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = read_csv('../../handson-ml/predictions_error.csv', index_col=0)\n",
    "error.to_csv('../../handson-ml/predictions_error.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# renomme la colonne 1 probability en prédiction\n",
    "myList = list(error.columns)\n",
    "myList[1] = 'Prediction'\n",
    "error.columns = myList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# création de la colonne error\n",
    "error.insert( 2, 'Error', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de remplissage de la colonne error\n",
    "def errorPred(row):\n",
    "    if row['SeriousDlqin2yrs'] == 0 and row['Prediction'] == 0:\n",
    "        row['Error'] = 'TN'\n",
    "    if row['SeriousDlqin2yrs'] == 0 and row['Prediction'] == 1:\n",
    "        row['Error'] = 'FP'\n",
    "    if row['SeriousDlqin2yrs'] == 1 and row['Prediction'] == 0:\n",
    "        row['Error'] = 'FN'\n",
    "    if row['SeriousDlqin2yrs'] == 1 and row['Prediction'] == 1:\n",
    "        row['Error'] = 'TP'\n",
    "    return row['Error']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplissage de la colonne error\n",
    "error['Error'] = error.apply(errorPred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcul de la matrice de confusion, accurancy et gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage de la matrice de confusion\n",
    "resultat = error['Error'].value_counts()\n",
    "resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de l'accurancy\n",
    "accuracy = (resultat[0] + resultat[2])/(resultat[0] + resultat[1] + resultat[2] + resultat[3])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de la matrice de gain\n",
    "matrice_gain = resultat[0]*500 - resultat[1]*500 + resultat[2]*0 - resultat[3]*2500\n",
    "matrice_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcul gain en fonction d'une valeur seuil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fonction de remplissage de la colonne error en prenant en compte une valeur seuil et retour du gain\n",
    "def gain_seuil(seuil):\n",
    "    def seuil_pred(row, seuil):\n",
    "        if row['1 probability'] > seuil and row['SeriousDlqin2yrs'] == 0:\n",
    "            row['Error'] = 'FP'\n",
    "        if row['1 probability'] > seuil and row['SeriousDlqin2yrs'] == 1:\n",
    "            row['Error'] = 'TP'\n",
    "        if row['1 probability'] < seuil and row['SeriousDlqin2yrs'] == 0:\n",
    "            row['Error'] = 'TN'\n",
    "        if row['1 probability'] < seuil and row['SeriousDlqin2yrs'] == 1:\n",
    "            row['Error'] = 'FN'\n",
    "        return row\n",
    "\n",
    "    for df in [error]:\n",
    "        df['Error'] = df[['Error', '1 probability', 'SeriousDlqin2yrs']].apply(seuil_pred, axis=1, seuil = seuil)\n",
    "\n",
    "    count = error['Error'].value_counts()\n",
    "    gain = 1\n",
    "    if \"TP\" not in  error['Error']:\n",
    "        if \"FP\" not in  error['Error']:\n",
    "            gain = count[0]*500 - count[1]*2500\n",
    "        else:\n",
    "            gain = count[0]*500 - count[1]*2500 - count[2]*500\n",
    "    else:\n",
    "        gain = count[0]*500 - count[1]*2500 - count[3]*500\n",
    "        \n",
    "    return gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# affichage de la courbe de gzin en fonction de la valeur seuil\n",
    "table = [gain_seuil(n/100) for n in range(1,100)]\n",
    "seuil = [(n/100) for n in range(1,100)]\n",
    "plt.plot(seuil, table)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calcul de la valeur max du gain et obtention du seuil optimal\n",
    "max_val = max(table)\n",
    "max_seuil = table.index(max_val)/100\n",
    "\n",
    "print(f\"le gain maximal est de {max_val} et il est obtenu en {max_seuil}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compter les valeurs dans la colonne error\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(error['SeriousDlqin2yrs'])\n",
    "c_pred = Counter(error['Error'])\n",
    "c_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcul de l'AUC (area under the courbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = error.loc[error['SeriousDlqin2yrs'] == 1] # Tous les Positif  \n",
    "neg = error.loc[error['SeriousDlqin2yrs'] == 0] # Tous les negatifs  \n",
    "x = 0 \n",
    "y = 0 # pour chaque 1 proba ( P ) dans toutes les 1 proba (P)\n",
    "for threshold_pos in pos['1 probability']: # pour chaque 1 Proba ( N ) dans toutes les 1 proba ( N )     \n",
    "    for threshold_neg in neg['1 probability']:         \n",
    "        if threshold_pos > threshold_neg:             \n",
    "            x += 1          \n",
    "        y += 1 \n",
    "print(x/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
